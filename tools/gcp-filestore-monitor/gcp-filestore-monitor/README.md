# GCP Filestore Monitor

The purpose of this project is to allow the monitoring of GCP Filestore volume usage metrics spanning across multiple projects. The solution is intended to be deployed to a Cloud function.

The function consist of an http endpoint which functionality depends on the HTTP method provided. The supported methods are:

- **POST** - Fetches the metrics from GCP converts them to Prometheus format and uploads it into a Cloud Storage blob for fast retrieval. Additionally to this, this method also triggers the filestore volume increase process if enabled and the threshold is exceeded.
- **GET** - Fast retrieval of the metrics. It downloads the blob generated by the POST call and returns the data to the caller in Prometheus format.

The Volume increase process is located in a separate solution (gcp-filestore-resize) which needs to be hosted on a separate cloud function. The monitor does not directly trigger this function, a task is generated in a Cloud Task Queue which takes care the increase function.

## Environment Variables

The following environment variables need to be set in order for the project to work properly.

| Name        | Description |
| ----------- | ----------- |
|SCOPE          | The scope for listing the projects. i.e. "organization/{number}", "folder/{number}". Required if PROJECT_ID is not provided.|
|PROJECT_ID     | Comma separated list of project names, no spaces. Required if SCOPE is not provided.|
|PROJECT_PATTERN| When scope is set, filters the projects matching this pattern. Required if scope is provided. i.e. ^.*$ (matches everything)|
|BUCKET_NAME    | The storage account where the results are going to be stored. Required.|
|LOCAL          | For local development. Accept values 0 or 1. If set to 1, it will try to login with gcloud credentials. Optional. |
|LOGLEVEL       | Logging level for the function (INFO, WARN, ERROR...). Optional.|
|RESIZE_ENABLED | Enable feature to trigger a call to the resize function|
|RESIZE_USAGE_THRESHOLD|Minimum Usage Percentage required for the process to call to the resize function |
|RESIZE_QUEUE_NAME| Cloud Task Queue name. Calls to the resize function are sent through this queue.|
|RESIZE_QUEUE_SA| Service Account used by the Cloud Task to trigger the gcp-filestore-resize cloud function |
|RESIZE_ENDPOINT| Url endpoint of the gcp-filestore-resize cloud function.|
|RESIZE_INCREASE_PERCENTAGE| Desired increase percentage for the volume. i.e. 10 |
|RESIZE_ENTERPRISE_MAX_CAPACITY| Overrides the max_capacity_gb property for Enterprise Tier filestores set on the config.json file.|

Additional configuration can be found inside the config.json file. It contains details regarding the diferent Filestore Tiers.

## Service Requirements

All the following solution services should be placed inside the same GCP Project.

- **Cloud Function** - This service is where the code should be published.
- **Cloud Storage** - Will store the metrics generated from the POST call into a blob and then will be read by the GET call.
- **Cloud Scheduler** - Used to periodically send a POST call to the function to regenerate the metrics.
- **Cloud Task Queue** - A task will be sent to this queue in order to trigger the filestore increase function. if the RESIZE_USAGE_THRESHOLD is exceeded

## Permissions

The cloud function itself, requires a Service Account with the following permissions:

| Permission  | Scope       |
| ----------- | ----------- |
|roles/monitoring.viewer | Organization/Folder scope|
|resourcemanager.projects.list | Organization/Folder scope|
|resourcemanager.projects.get | Organization/Folder scope|
|file.instances.get | Organization/Folder scope|
|file.instances.list | Organization/Folder scope|
|roles/secretmanager.secretAccessor | Host project scope|
|roles/cloudtasks.enqueuer | Host project scope|
|roles/storage.objectAdmin | Cloud Storage Bucket scope|

While the Cloud Scheduler and Cloud Task Queue need below permissions to trigger the Cloud Function.

| Permission  | Scope       |
| ----------- | ----------- |
|roles/cloudfunctions.invoker| Host project scope |

## Execution

The POST request expects to receive a json with a property called monitor_period which defines search scope of the monitor. If not provided, a default value is 300 seconds is used. Values lower than 2 minutes (120 seconds) might provide missing information.

```
{ 
    "monitor_period": 300
}
```

For running on local environment, below command needs to be executed. It will return an endpoint which can be called to trigger the code.

```
python -m venv .venv
.venv\scripts\activate
pip install -r requirements.txt
functions-framework --target filestore_monitor
```

In a different session, call the endpoint returned by the previous command.
```
curl -X POST -H "Content-Type: application/json" -H "Accept: */*" -d '{\"monitor_period\": 120 }' <url>

curl -X GET -H "Accept: */*" <url>
```

The result should look as shown below.
```
# HELP gcp_filestore_usage_percentage Usage percentage of GCP Filestore volumes
# TYPE gcp_filestore_usage_percentage gauge
gcp_filestore_usage_percentage{location="us-east1",name="instance1",project="my-project",volume="my_vol"} 0.0
gcp_filestore_usage_percentage{location="us-east1",name="instance2",project="my-project",volume="my_vol"} 40.28
gcp_filestore_usage_percentage{location="us-east1",name="instance3",project="my-project",volume="my_vol"} 1.74
```

## Deployment to GCP

Creates and deployes the cloud function. If function already exists, code gets redeployed. Must be executed on the functions root directory in order to push the code.

When setting environment variables in a single string, DO NOT add spaces to separate the variables.

```
gcloud functions deploy {function_name} --runtime python39 --trigger-http --entry-point filestore_monitor --region {region} --service-account {service_account} --set-env-vars "SCOPE={folder/org scope},PROJECT_PATTERN=^.*$,RESIZE_ENABLED=0,RESIZE_USAGE_THRESHOLD=80,RESIZE_QUEUE_NAME={cloud_task_queue},RESIZE_QUEUE_SA={task_service_account},RESIZE_ENDPOINT={resize_function_url},RESIZE_INCREASE_PERCENTAGE=10,BUCKET_NAME={bucket_name},BLOB_NAME=filestore-monitor/filestore_collector.prom"
```

If the function needs to be redeployed without modifying the environment variables a shorter version of the command can be executed.
```
gcloud functions deploy {function_name} --runtime python39 --trigger-http --entry-point filestore_monitor --region {region}
```